{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-27T07:10:18.589228300Z",
     "start_time": "2023-10-27T07:10:16.152540500Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.pix2pixHD.networks import MultiscaleDiscriminator\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "d = MultiscaleDiscriminator(3, 64, 3, 3)\n",
    "\n",
    "image = Image.open('../../../data/train_img/aachen_000000_000019_leftImg8bit.png')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "img_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "res = d(img_tensor.float())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T07:10:19.691609400Z",
     "start_time": "2023-10-27T07:10:18.592252Z"
    }
   },
   "id": "ec18cefa582448cb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "([tensor([[[[0.4584, 0.7477, 0.7112,  ..., 0.4360, 0.5054, 0.4916],\n            [0.6826, 0.8056, 0.8958,  ..., 0.4548, 0.5023, 0.4237],\n            [0.6336, 0.7062, 0.7297,  ..., 0.5508, 0.5543, 0.5674],\n            ...,\n            [0.5152, 0.5679, 0.5363,  ..., 0.4930, 0.4814, 0.4822],\n            [0.5235, 0.4836, 0.4134,  ..., 0.4196, 0.4067, 0.4676],\n            [0.4717, 0.4994, 0.4623,  ..., 0.5111, 0.4276, 0.4904]]]],\n         grad_fn=<SigmoidBackward0>),\n  tensor([[[[0.5671, 0.5212, 0.7029,  ..., 0.7207, 0.6422, 0.4980],\n            [0.5228, 0.4494, 0.8290,  ..., 0.8094, 0.6423, 0.5412],\n            [0.4384, 0.5691, 0.8331,  ..., 0.4592, 0.4050, 0.5325],\n            ...,\n            [0.5010, 0.5685, 0.5499,  ..., 0.6018, 0.4785, 0.4792],\n            [0.5122, 0.5422, 0.4463,  ..., 0.5238, 0.4818, 0.4624],\n            [0.4759, 0.5058, 0.4986,  ..., 0.4987, 0.4898, 0.4842]]]],\n         grad_fn=<SigmoidBackward0>),\n  tensor([[[[0.5110, 0.3307, 0.4045,  ..., 0.6790, 0.5686, 0.5893],\n            [0.4598, 0.3581, 0.4774,  ..., 0.4244, 0.5770, 0.4814],\n            [0.6726, 0.6106, 0.6874,  ..., 0.4667, 0.5161, 0.4991],\n            ...,\n            [0.6008, 0.5297, 0.5448,  ..., 0.5043, 0.4852, 0.5168],\n            [0.5442, 0.5230, 0.6611,  ..., 0.5199, 0.5282, 0.5213],\n            [0.5098, 0.5984, 0.6292,  ..., 0.4710, 0.5218, 0.5198]]]],\n         grad_fn=<SigmoidBackward0>)],\n torch.Size([1, 1, 131, 259]))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, res[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T07:10:19.709419300Z",
     "start_time": "2023-10-27T07:10:19.691609400Z"
    }
   },
   "id": "2b8cd4c41deab669"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T07:10:19.715438800Z",
     "start_time": "2023-10-27T07:10:19.707884600Z"
    }
   },
   "id": "6c679aee107d3127"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
